#!/usr/bin/env python3

from flask import Flask, json, request, jsonify, redirect, url_for
from werkzeug.serving import make_server
import sys
from os import listdir
from os.path import join, dirname, abspath, isdir
from threading import Thread, Lock, Event
from argparse import ArgumentParser
import time
from collections import namedtuple
import logging
from datetime import datetime

from util import pretty_print
from util.rapl import RAPLCounter


def add_third_party_dir(f):
    base_path = dirname(abspath(f))
    tp_dir = join(base_path, "third_party")

    for e in listdir(tp_dir):
        if isdir(join(tp_dir, e)):
            sys.path.append(join(tp_dir, e))

add_third_party_dir(__file__)
from eris import ErisCtrl, ErisCtrlError
from pareto import paretoOptimize

try:
    from eris_model import Eris
    from hardware_model import Hardware
except ImportError:
    print("Model files are missing. Abort", file=sys.stderr)
    sys.exit(1)



# All the REST API stuff
app = Flask(__name__)

@app.route("/", methods=["GET"])
def index():
    return redirect(url_for("service_status"))

@app.route("/configurations", methods=["GET"])
def configurations():
    global euf_mgr

    configs, active_config = euf_mgr.get_configurations()

    json_configs = []

    max_freq = max(Hardware.config["freq"])
    min_freq = min(Hardware.config["freq"])

    max_ee = 0
    max_tps = 0
    for c in configs:
        ee = 1/c.epr

        data = {}
        data["cpuCount"] = c.cpus
        data["avgCoreFrequency"] = c.freq
        data["avgCoreFrequencyLevel"] = (c.freq - min_freq) / (max_freq - min_freq) * 100
        data["uncoreFrequency"] = 2400000
        data["uncoreFreqeuncyLevel"] = 100
        data["relativePerformance"] = c.tps
        data["relativeEE"] = ee
        data["active"] = False if active_config is None else c == active_config

        json_configs.append(data)

        if ee > max_ee:
            max_ee = ee
        if c.tps > max_tps:
            max_tps = c.tps

    for jc in json_configs:
        jc["relativePerformance"] = jc["relativePerformance"] / max_tps * 100
        jc["relativeEE"] = jc["relativeEE"] / max_ee * 100

    return jsonify({"sockets" : [{
            "logicalId" : 0,
            "configurations" : json_configs,
            "adapting" : False,
            "reevalLeft" : 0
        }]})

@app.route("/servicestatus", methods=["GET"])
def service_status():
    global euf_mgr

    euf_on = euf_mgr.euf()
    return jsonify({"adaptOn" : False, "eclOn" : euf_on})

@app.route("/services/<stype>/<status>", methods=["POST"])
def services(stype, status):
    global euf_mgr

    if stype == "adapton":
        pass
    elif stype == "eclon":
        if int(status) == 1:
            euf_mgr.euf_on()
        else:
            euf_mgr.euf_off()
    else:
        return '',400

    return '',200

@app.route("/benchmark/sessions")
def sessions():
    return jsonify({"managedBenchmarks" : [ { "name" : "sigmod-demo" } ]})

@app.route("/benchmark/setbenchmark/<session>/<bench>", methods=["POST"])
def set_benchmark(session, bench):
    global euf_mgr

    success = euf_mgr.set_benchmark(bench)

    return '', 200 if success else 400

@app.route("/benchmark/setprofile/<session>/<profile>", methods=["POST"])
def set_profile(session, profile):
    success = euf_mgr.set_profile(profile)

    return '', 200 if success else 400

class FlaskThread(Thread):
    def __init__(self, app, euf):
        super().__init__()

        # Disable flask logging completely
        logging.getLogger('werkzeug').setLevel(logging.ERROR)

        # Create the flask server using werkzeug
        self._server = make_server("localhost", 5000, app)
        self._ctx = app.app_context()
        self._ctx.push()

        # Save the EUF thread in the global context so that we can access it from
        # inside the requests
        global euf_mgr
        euf_mgr = euf

    def run(self):
        self._server.serve_forever()

    def shutdown(self):
        self._ctx.pop()
        self._server.shutdown()


class EUFThread(Thread):
    class Config(namedtuple("Config", ["freq", "cores", "ht", "cpus", "ipc", "power", "tps", "epr"])):
        __slots__ = ()

        def __eq__(self, other):
            if self is None or other is None:
                return False

            return self.freq == other.freq and self.cores == other.cores and self.ht == other.ht

    def __init__(self, ectrl, event):
        super().__init__()

        # Various cosmetic settings
        self._history_length = 300
        self._refresh_time = 1000

        self._ectrl = ectrl
        self._lock = Lock()
        self.eufon = True

        self._loglines = []

        self._event = event

        # Our internal monitoring data
        self._last_refresh = None
        try:
            self._rapl_counters = RAPLCounter()
        except ValueError:
            self._rapl_counters = None

        self._monitoring_data = {
            "power" : [],
            "performance" : []
        }

        # Register the ERIS performance counters
        self._counters = {}
        for ctr in ectrl.counters():
            if ctr.dist_name == "Tasks.Started":
                self._counters["started"] = ctr.monitor()
            if ctr.dist_name == "Tasks.Active":
                self._counters["active"] = ctr.monitor()
            elif ctr.dist_name == "Tasks.Finished":
                self._counters["finished"] = ctr.monitor()
            elif ctr.dist_name == "Tasks.Latency Average":
                self._counters["latency"] = ctr.monitor()

        # Get all the workers
        self.workers = ectrl.workers()

        # Get the demo session
        self.session = ectrl.session("demo-sigmod")

        self._log("Available benchmarks:")
        for n, b in self.session.benchmarks.items():
            self._log("{}: {}".format(n, b.name))

        self._log("Available profiles:")
        for n, p in self.session.profiles.items():
            self._log("{}: {}".format(n, p.name))

        # Internal management data
        self._update = True
        self._state = None

        self._configurations = None
        self._active_configuration = None

        self._benchmark_configurations = {}
        self._pregenerate_configurations()

    # Other support functions
    def get_configurations(self):
        with self._lock:
            return self._configurations, self._active_configuration

    def set_benchmark(self, bench_id):
        with self._lock:
            return self.session._activate_benchmark(bench_id)

    def set_profile(self, profile_id):
        with self._lock:
            return self.session._activate_profile(profile_id)

    def euf_on(self):
        with self._lock:
            self.eufon = True
            self._update = True

    def euf_off(self):
        with self._lock:
            self.eufon = False
            self._update = True

    def euf(self):
        with self._lock:
            return self.eufon

    def _log(self, string):
        self._loglines.append(string)

        print(string)

    # EUF related functions
    def _benchmark_states(self, benchmark_session):
        state = {}
        for n, b in benchmark_session.benchmarks.items():
            state[n] = (b.state(False), b.active(False))

        return state

    def _bench_changed(self):
        self.session._update()
        old_state = self._state
        self._state = self._benchmark_states(self.session)


        if old_state is None:
            return True

        changed = False
        for b in self._state:
            os, oa = old_state[b]
            ns, na = self._state[b]

            if os != ns:
                self._log("State changed for {}: {} to {}".format(b, os, ns))
                changed = True
            elif oa != na:
                self._log("Active changed for {}: {} to {}".format(b, oa, na))
                changed = True

        return changed

    def _bench_running(self):
        for b in self._state:
            s, _ = self._state[b]

            if s == "Running":
                return (True, self.session.benchmarks[b])

        return (False, None)

    def _bench_loading(self):
        for b in self._state:
            s, _ = self._state[b]

            if s == "Loading":
                return (True, self.session.benchmarks[b])

        return (False, None)

    def _need_adaptation(self):
        if self._active_configuration is None:
            return False, None
        if len(self._configurations) == 1:
            return False, None

        started_ctr = self._counters["started"].values(False)
        active_ctr = self._counters["active"].values(False)
        if len(started_ctr) == 0 or len(active_ctr) == 0:
            return False, None

        started = started_ctr[-1].value
        active = active_ctr[-1].value
        if started > active:
            needed_tps = started
        else:
            needed_tps = active
        available_tps = self._active_configuration.tps

        if abs(needed_tps - available_tps) > (needed_tps * 0.05):
            self._log("Need adaptation: {} requested T/s vs {} provided T/s".format(needed_tps, available_tps))
            return True, needed_tps

        return False, None

    def _pregenerate_configurations(self):
        for n in self.session.benchmarks:
            b = self.session.benchmarks[n]

            if b.name in self._benchmark_configurations:
                continue

            self._log("Generating configurations for {}".format(b.name))

            # Generate all possible configurations based on the models
            all_configurations = []
            for freq in Hardware.config['freq']:
                for cores in Hardware.config['cores']:
                    for ht in Hardware.config['ht']:
                        cpus = (ht+1)*cores
                        params = Eris(cpus, ht).benchmarks(b.name)
                        ipc = Hardware.IPC(
                                memory_heaviness=params["memory_heaviness"](),avx_heaviness=params["avx_heaviness"](), branch_heaviness=params["branch_heaviness"](),
                                compute_heaviness=params["compute_heaviness"](),cache_heaviness=params["cache_heaviness"](),
                                cpus=cpus,freq=freq,ht=ht)
                        p_pkg = Hardware.P_PKG(
                                memory_heaviness=params["memory_heaviness"](),avx_heaviness=params["avx_heaviness"](),compute_heaviness=params["compute_heaviness"](),
                                IPC=ipc,freq=freq,cpus=cpus,ht=ht)
                        p_core = Hardware.P_Cores(
                                nomemory_heaviness=params["nomemory_heaviness"](),avx_heaviness=params["avx_heaviness"](),compute_heaviness=params["compute_heaviness"](),
                                IPC=ipc,freq=freq,cpus=cpus,ht=ht)
                        p_ram = Hardware.P_Ram(memory_heaviness=params["memory_heaviness"](),
                                IPC=ipc,freq=freq,cpus=cpus,ht=ht)
                        tps = (freq*1000)/(params["ipt"]()/ipc)

                        power = p_pkg + p_ram
                        epr = power/tps

                        all_configurations.append(EUFThread.Config(freq=freq, cores=cores, ht=True if ht == 1 else False,
                                                                   cpus=cpus, ipc=ipc, power=power, tps=tps, epr=epr))

            # Reduce the number of configurations to the pareto optimal ones
            pareto_configurations =  [EUFThread.Config(**pc) for pc in paretoOptimize([c._asdict() for c in all_configurations], ["<power", ">tps"])]
            self._log("Generated {} configurations, of which {} are pareto optimal".format(len(all_configurations), len(pareto_configurations)))

            # Save the configurations in our internal buffer
            self._benchmark_configurations[b.name] = {"all": all_configurations, "pareto": pareto_configurations}

    def _update_configurations(self):
        self._configurations = []
        if not self.eufon:
            self._log("EUF disabled - using max performance configuration")

            freq = max(Hardware.config["freq"])
            cores = max(Hardware.config["cores"])

            self._configurations.append(EUFThread.Config(freq=freq,
                                                         cores=cores,
                                                         ht=True,
                                                         cpus=2*cores,
                                                         ipc=1, power=1, tps=1, epr=1))
            return

        loading, b = self._bench_loading()
        if loading:
            self._log("{} is currently loading - using max performance configuration".format(b.name))

            freq = max(Hardware.config["freq"])
            cores = max(Hardware.config["cores"])

            self._configurations.append(EUFThread.Config(freq=freq,
                                                         cores=cores,
                                                         ht=True,
                                                         cpus=2*cores,
                                                         ipc=1, power=1, tps=1, epr=1))

            return

        running, b = self._bench_running()
        if not running:
            self._log("No benchmark running")
            # Add a minimal configuration that we use when nothing is running and no
            # tasks are outstanding.
            self._configurations.append(EUFThread.Config(freq=min(Hardware.config["freq"]),
                                                         cores=min(Hardware.config["cores"]),
                                                         ht=False,
                                                         cpus=min(Hardware.config["cores"]),
                                                         ipc=1, power=1, tps=1, epr=1))

            # Also add the last active configuration if there is one and if its not
            # already the idle config. We can use this configuration if there are
            # still requests outstanding.
            if self._active_configuration is not None and \
                    self._active_configuration != self._configurations[0]:
                self._configurations.append(self._active_configuration)

            return

        self._log("{} is currently running - using pregenerated configuration".format(b.name))

        self._configurations = self._benchmark_configurations[b.name]["pareto"]

    def _find_best_configuration(self, target_tps=None, last_best=None):
        if len(self._configurations) == 1:
            return self._configurations[0]

        best = last_best
        for c in self._configurations:
            if target_tps is None:
                if best is None or c.power < best.power:
                    best = c
            else:
                if best is None:
                    best = c
                elif c.tps >= target_tps:
                    if c.power < best.power:
                        best = c
                elif c.tps >= best.tps:
                    best = c

        return best

    def _apply_configuration(self, config):
        if self._active_configuration is not None and self._active_configuration == config:
            self._active_configuration = config
            return

        workers = []
        for i in range(config.cores):
            workers.append(i)
        if config.ht:
            for i in range(config.cores):
                workers.append(i + max(Hardware.config['cores']))

        frequency = config.freq

        self._log("Applying configuration: {} @{}MHz".format(pretty_print(workers), frequency/1000))

        for w in self.workers:
            w.frequency(frequency)
            if w.localid in workers:
                w.enable()
            else:
                w.disable()

        self._active_configuration = config

    # Data collecting methods
    def _pull_performance_data(self):
        self._ectrl._pull_monitoring_data()

        # Get the latest performance value
        perf_vals = self._counters["finished"].values(False)
        if len(perf_vals) > 0:
            actual_perf = perf_vals[-1].value
            estimated_perf = self._active_configuration.tps

            self._monitoring_data["performance"].append((datetime.now(), actual_perf, estimated_perf))

    def _pull_power_data(self):
        if self._rapl_counters is None:
            self._monitoring_data["power"].append((datetime.now(), 0, self._active_configuration.power))
            return

        rapl_counters = RAPLCounter()

        diff = self._rapl_counters - rapl_counters

        actual_power = diff.domain(0).counter("package-0").watts + diff.domain(0).counter("dram").watts
        estimated_power = self._active_configuration.power

        self._monitoring_data["power"].append((diff.timestamp, actual_power, estimated_power))
        self._rapl_counters = rapl_counters

    def _update_monitoring_data(self):
        if self._last_refresh is None or \
                (datetime.now()-self._last_refresh).total_seconds() * 1000 > self._refresh_time:
            self._pull_performance_data()
            self._pull_power_data()

            self._last_refresh = datetime.now()

    # Our main loop
    def run(self):
        while not self._event.is_set():
            with self._lock:
                if self._bench_changed() or self._update:
                    # We need to update - do it
                    self._update_configurations()

                    best = self._find_best_configuration()
                    self._apply_configuration(best)
                    self._update = False

                # Check if we need to adapt to a more or less power hungry configuration
                adapt, target_tps = self._need_adaptation()
                if adapt:
                    best = self._find_best_configuration(target_tps, self._active_configuration)
                    self._apply_configuration(best)

            # Wait for another update
            time.sleep(1)

            # Output the latest counter values
            self._update_monitoring_data()


# Main
def run(ectrl):
    # Prepare ERIS
    ectrl.energy_management(False, False)       # Turn of ERIS' energy control loop (we are doing this now!)
    for w in ectrl.workers():                   # Turn on all ERIS workers
        w.enable()

    kill_event = Event()

    # Start the EUF and flask threads
    euf_thread = EUFThread(ectrl, kill_event)
    flask_thread = FlaskThread(app, euf_thread)

    euf_thread.start()
    flask_thread.start()

    # Wait for the EUF thread to join
    try:
        euf_thread.join()
    except KeyboardInterrupt:
        kill_event.set()
        euf_thread.join()

    # Shutdown everything
    flask_thread.shutdown()
    flask_thread.join()

def main():
    # Parse the command line arguments
    arguments = ArgumentParser(description="EUF manager for ERIS")
    arguments.add_argument("--url", help="The url where the ERIS server can be reached (default=localhost)",
            type=str, dest="url", default="localhost")
    arguments.add_argument("--port", help="The port at which the ERIS server can be reached (default=5189)",
            type=int, dest="port", default=5189)
    arguments.add_argument("--user", help="The user that should be used to connect to ERIS (default=euf)",
            type=str, dest="user", default="euf")
    arguments.add_argument("--passwd", help="The password that should be used to connect to ERIS (default=euf)",
            type=str, dest="passwd", default="euf")
    arguments.add_argument("--nocurses", help="Disable curses output", action="store_true", default=False,
            dest="nocurses")

    parsed_args = arguments.parse_args()

    if not parsed_args.nocurses:
        print("Curses are not supported")
        sys.exit(1)

    # Connect to ERIS
    try:
        with ErisCtrl(parsed_args.url, parsed_args.port, parsed_args.user, parsed_args.passwd) as ectrl:
            run(ectrl)
    except ErisCtrlError:
        print("Failed to connect to ERIS!")
        sys.exit(1)

if __name__ == "__main__":
    main()
